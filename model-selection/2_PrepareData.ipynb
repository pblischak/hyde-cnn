{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing Data for CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from ete3 import Tree\n",
    "from random import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_pairs = [\n",
    "    (\"1\",\"2\"),\n",
    "    (\"3\",\"4\"),\n",
    "    (\"1\",\"3\"),\n",
    "    (\"2\",\"3\"),\n",
    "    (\"1\",\"4\"),\n",
    "    (\"2\",\"4\"),\n",
    "    (\"1\",\"5\"),\n",
    "    (\"2\",\"5\"),\n",
    "    (\"3\",\"5\"),\n",
    "    (\"4\",\"5\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sim_data(sim_name, max_gt):\n",
    "    trees = glob(\"{0}/{0}_recomb*.tre\".format(sim_name))\n",
    "    nsims = len(trees)\n",
    "    X = np.zeros((nsims,max_gt,10))\n",
    "    i = 0\n",
    "    print(\"Processing {} trees ({} simulations)...\".format(sim_name,nsims))\n",
    "    for file in trees:\n",
    "        coals = {op : [] for op in ordered_pairs}\n",
    "        with open(file) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                line = line.split(\"]\")[1]\n",
    "                t = Tree(line)\n",
    "                for pr in ordered_pairs:\n",
    "                    coals[pr].append(t.get_distance(pr[0],pr[1])/2.0)\n",
    "        mat = np.array([coals[k] for k in ordered_pairs]).T\n",
    "        mat_mean = np.mean(mat)\n",
    "        mat_std  = np.std(mat)\n",
    "        X[i,:mat.shape[0],:] = (mat-mat_mean)/mat_std\n",
    "        i += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we will run the simulated data to generate the input images. We can get the maximum number of trees by looking at the line counts in each of the simulated gene tree files using `wc -l *.tre | sort | tail` in each of the folders with simulated data. For these data, the maximum number of gene trees is 394."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing no_hyb trees (50000 simulations)...\n"
     ]
    }
   ],
   "source": [
    "no_hyb = process_sim_data(\"no_hyb\",394)\n",
    "np.savez_compressed('no_hyb_recomb.npz', X=no_hyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing one_hyb trees (50000 simulations)...\n"
     ]
    }
   ],
   "source": [
    "one_hyb = process_sim_data(\"one_hyb\",394)\n",
    "np.savez_compressed('one_hyb_recomb.npz', X=one_hyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hyb_mig trees (50000 simulations)...\n"
     ]
    }
   ],
   "source": [
    "hyb_mig = process_sim_data(\"hyb_mig\",394)\n",
    "np.savez_compressed('hyb_mig_recomb.npz', X=hyb_mig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing two_hyb trees (50000 simulations)...\n"
     ]
    }
   ],
   "source": [
    "two_hyb = process_sim_data(\"two_hyb\",394)\n",
    "np.savez_compressed('two_hyb_recomb.npz', X=two_hyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 394, 10)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.concatenate((np.load('no_hyb_recomb.npz')[\"X\"],\n",
    "                        np.load('one_hyb_recomb.npz')[\"X\"],\n",
    "                        np.load('hyb_mig_recomb.npz')[\"X\"],\n",
    "                        np.load('two_hyb_recomb.npz')[\"X\"]),axis=0)\n",
    "print(X_all.shape)\n",
    "y_all = np.stack((np.repeat((1,0,0,0), 50000),\n",
    "                  np.repeat((0,1,0,0), 50000),\n",
    "                  np.repeat((0,0,1,0), 50000),\n",
    "                  np.repeat((0,0,0,1), 50000)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will shuffle the indices to randomize the order of the different simulated models and divide\n",
    "everything into a training, validation, and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shf = list(range(200000))\n",
    "shuffle(shf)\n",
    "X_shf = X_all[shf,:,:]\n",
    "y_shf = y_all[shf,:]\n",
    "xtrain, xval, xtest = X_shf[:140000,:,:], X_shf[140000:170000,:,:], X_shf[170000:,:,:]\n",
    "ytrain, yval, ytest = y_shf[:140000,:], y_shf[140000:170000,:], y_shf[170000:,:]\n",
    "np.savez_compressed(\n",
    "    'all_sims_recomb.npz',\n",
    "    xtrain=xtrain,\n",
    "    xval=xval,\n",
    "    xtest=xtest,\n",
    "    ytrain=ytrain,\n",
    "    yval=yval,\n",
    "    ytest=ytest\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 394, 10)\n"
     ]
    }
   ],
   "source": [
    "X_hyb = np.concatenate((np.load('no_hyb_recomb.npz')[\"X\"],\n",
    "                        np.load('one_hyb_recomb.npz')[\"X\"],\n",
    "                        np.load('two_hyb_recomb.npz')[\"X\"]),axis=0)\n",
    "print(X_hyb.shape)\n",
    "y_hyb = np.stack((np.repeat((1,0,0), 50000),\n",
    "                  np.repeat((0,1,0), 50000),\n",
    "                  np.repeat((0,0,1), 50000)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hshf = list(range(150000))\n",
    "shuffle(hshf)\n",
    "X_shyb = X_hyb[hshf,:,:]\n",
    "y_shyb = y_hyb[hshf,:]\n",
    "np.savez_compressed(\n",
    "    'hyb_sims_recomb.npz',\n",
    "    xtrain=X_shyb[:105000,:,:],\n",
    "    xval=X_shyb[105000:127500,:,:],\n",
    "    xtest=X_shyb[127500:,:,:],\n",
    "    ytrain=y_shyb[:105000,:],\n",
    "    yval=y_shyb[105000:127500,:],\n",
    "    ytest=y_shyb[127500:,:]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a gzipped tarball of the simulated gene trees since we are done processing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd no_hyb && tar czf no_hyb_recomb.tar.gz no_hyb_recomb*.tre && cd ..\n",
    "cd one_hyb && tar czf one_hyb_recomb.tar.gz one_hyb_recomb*.tre && cd ..\n",
    "cd hyb_mig && tar czf hyb_mig_recomb.tar.gz hyb_mig_recomb*.tre && cd ..\n",
    "cd two_hyb && tar czf two_hyb_recomb.tar.gz two_hyb_recomb*.tre && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
